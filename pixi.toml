[project]
name = "docintel"
version = "0.1.0"
description = "Pixi-managed environment for the clinical trial knowledge mining platform."
channels = ["https://conda.modular.com/max", "conda-forge"]
platforms = ["linux-64"]

[dependencies]
python = ">=3.11,<3.13"
aiohttp = "*"
tenacity = "*"
openai = "*"
modular = "*"
mojo = "*"
pydantic = "*"
pydantic-settings = "*"
pytest = "*"
pytest-asyncio = "*"
httpx = "*"
docling = ">=2.45.0,<3"
transformers = "*"
accelerate = "*"
pip = "*"
pymupdf = ">=1.26.1,<2"
psycopg = "*"
pgvector = "*"
psycopg-pool = "*"
spacy = "*"
networkx = "*"
numpy = "*"
scikit-learn = "*"
rich = "*"
click = "*"
beautifulsoup4 = ">=4.14.2,<5"
lxml = ">=5.4.0,<6"
gradio = ">=5.49.0,<6"

[pypi-dependencies]
pgvector = "*"
medspacy = "*"
graspologic = "*"
fuzzywuzzy = "*"
python-levenshtein = "*"
docintel = { path = ".", editable = true }

[tasks]
lint = "python -m compileall src"
warm-docling = "env MODULAR_CACHE_DIR=$(pwd)/models LD_LIBRARY_PATH=/usr/local/cuda-12.8/lib64:$LD_LIBRARY_PATH max warm-cache --model ibm-granite/granite-docling-258M --devices=gpu --quantization-encoding bfloat16 --enable-structured-output"
max-serve = "bash scripts/start_max_server.sh"
ingest-vocab = "python scripts/ingest_vocabularies.py"



